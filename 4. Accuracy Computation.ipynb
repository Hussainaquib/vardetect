{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os, warnings, tensorflow as tf\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information\n",
    "\n",
    "We load pre-trained models to verify the accuracy figures.  \n",
    "Training code will be released at a later date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl.fashionmnist_dsl import FashionMNISTDSL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load confidential dataset $\\mathcal{D}_C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data\n",
      "datasets/fashionmnist/train-images-idx3-ubyte\n",
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "Loading val data\n",
      "datasets/fashionmnist/train-images-idx3-ubyte\n",
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "Loading test data\n",
      "datasets/fashionmnist/t10k-images-idx3-ubyte\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "train_dsl = FashionMNISTDSL(batch_size = 100, mode='train', normalize_channels=False, shuffle_each_epoch=False, seed=666)\n",
    "val_dsl   = FashionMNISTDSL(batch_size = 100, mode='val', normalize_channels=False, shuffle_each_epoch=False, seed=666)\n",
    "test_dsl  = FashionMNISTDSL(batch_size = 100, mode='test', normalize_channels=False, shuffle_each_epoch=False, seed=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, channels = train_dsl.get_sample_shape()\n",
    "\n",
    "is_multilabel = train_dsl.is_multilabel()\n",
    "num_classes = train_dsl.get_num_classes()\n",
    "num_batches = train_dsl.get_num_batches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load attacker datasets $\\mathcal{D}_A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syn-Uniform Retraining (Tramer _et al._ [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl.uniform_dsl import UniformDSL\n",
    "\n",
    "sample_shape = (width, height, channels)\n",
    "uniform_dsl = UniformDSL(batch_size=100, mode='train', shape=sample_shape, sample_limit=1000, seed=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNet samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data\n",
      "datasets/Imagenet64/train_data_batch_1.npy\n"
     ]
    }
   ],
   "source": [
    "from dsl.imagenet_dsl import ImagenetDSL\n",
    "\n",
    "resize = (width, height)\n",
    "img_noise_train_dsl = ImagenetDSL(batch_size=100, mode='train', resize=resize, normalize_channels=True, num_to_keep=1000, start_batch=1, end_batch=1, seed=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow version 1.14.0 has been patched using tfdeterminism version 0.3.0\n",
      "TensorFlow version 1.14.0 has been patched using tfdeterminism version 0.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from models.deepcnn import DeepCNN\n",
    "from models.vae import NewHSVNVAE\n",
    "from models.defended_model import DefenseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Adam Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.compat.v1.variable_scope(\"true_model\", reuse=tf.AUTO_REUSE):\n",
    "    true_model = DeepCNN(\n",
    "        batch_size=100,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        channels=channels,\n",
    "        num_classes=num_classes,\n",
    "        multilabel=is_multilabel,\n",
    "        is_training=False,\n",
    "        var_prefix='true_model'\n",
    "    )\n",
    "\n",
    "with tf.compat.v1.variable_scope(\"copy_model\"):\n",
    "    copy_model = DeepCNN(\n",
    "        batch_size=100,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        channels=channels,\n",
    "        num_classes=num_classes,\n",
    "        multilabel=is_multilabel,\n",
    "        is_training=True,\n",
    "        var_prefix='copy_model',\n",
    "        learning_rate=0.001\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "undefended_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfg import cfg, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From models/vae.py:275: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From models/vae.py:275: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From models/vae.py:294: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "Tensor(\"vae/Decoder/conv2d_transpose/LeakyRelu:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"vae/Decoder/conv2d_transpose_1/LeakyRelu:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"vae/Decoder/conv2d_transpose_2/LeakyRelu:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"vae/Decoder/conv2d_transpose_3/LeakyRelu:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"vae/Decoder/conv2d_transpose_4/Sigmoid:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "WARNING:tensorflow:From models/vae.py:337: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Tensor(\"vae/Decoder_1/conv2d_transpose/LeakyRelu:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"vae/Decoder_1/conv2d_transpose_1/LeakyRelu:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"vae/Decoder_1/conv2d_transpose_2/LeakyRelu:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"vae/Decoder_1/conv2d_transpose_3/LeakyRelu:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"vae/Decoder_1/conv2d_transpose_4/Sigmoid:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"vae\", reuse=tf.AUTO_REUSE):\n",
    "    vae = NewHSVNVAE(\n",
    "            batch_size=cfg.batch_size,\n",
    "            height=height, width=width,\n",
    "            channels=channels,\n",
    "            num_classes=2,\n",
    "            is_training=False,\n",
    "            z_size=32,\n",
    "            random_draws=1,\n",
    "            noise_mean=5.0\n",
    "         )\n",
    "    \n",
    "    defended_model = DefenseModel(\n",
    "        true_model,\n",
    "        vae,\n",
    "        threshold=[0.1, 0.1],\n",
    "        defender_type=\"vae_svm\",\n",
    "        use_recon_input=False\n",
    "    )\n",
    "    \n",
    "    oracle_model = defended_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "defended_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we show the accuracy of defended vs. undefended models on pretrained models for various attackers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syn extracted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from modeldir/fashionmnist-syn-undefended/model_epoch_49\n"
     ]
    }
   ],
   "source": [
    "logdir_copy = os.path.join('modeldir/fashionmnist-syn-undefended/')\n",
    "undefended_saver.restore(sess, tf.train.latest_checkpoint(logdir_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 25.33%\n"
     ]
    }
   ],
   "source": [
    "compute_agreement_and_accuracy(true_model, copy_model, sess, test_dsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarDefend-Defended $S_D$ ($10,000$ budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from modeldir/fashionmnist-syn-defended/model_epoch_49\n"
     ]
    }
   ],
   "source": [
    "logdir_copy = os.path.join('modeldir/fashionmnist-syn-defended/')\n",
    "defended_saver.restore(sess, tf.train.latest_checkpoint(logdir_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 7.56%\n"
     ]
    }
   ],
   "source": [
    "compute_agreement_and_accuracy(true_model, copy_model, sess, test_dsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvPD Extracted Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undefended (100K Budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from modeldir/fashionmnist-advpd-undefended/model_epoch_99\n"
     ]
    }
   ],
   "source": [
    "logdir_copy = os.path.join('modeldir/fashionmnist-advpd-undefended/')\n",
    "undefended_saver.restore(sess, tf.train.latest_checkpoint(logdir_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 81.15%\n"
     ]
    }
   ],
   "source": [
    "compute_agreement_and_accuracy(true_model, copy_model, sess, test_dsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarDetect-Defended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from modeldir/fashionmnist-advpd-defended/model_epoch_99\n"
     ]
    }
   ],
   "source": [
    "logdir_copy = os.path.join('modeldir/fashionmnist-advpd-defended/')\n",
    "defended_saver.restore(sess, tf.train.latest_checkpoint(logdir_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 75.87%\n"
     ]
    }
   ],
   "source": [
    "compute_agreement_and_accuracy(true_model, copy_model, sess, test_dsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvPD Extracted Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undefended (100K Budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from modeldir/fashionmnist-npd-undefended/model_step_4438\n"
     ]
    }
   ],
   "source": [
    "logdir_copy = os.path.join('modeldir/fashionmnist-npd-undefended/')\n",
    "undefended_saver.restore(sess, tf.train.latest_checkpoint(logdir_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 80.77%\n"
     ]
    }
   ],
   "source": [
    "compute_agreement_and_accuracy(true_model, copy_model, sess, test_dsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from modeldir/fashionmnist-npd-defended/model_step_4\n"
     ]
    }
   ],
   "source": [
    "logdir_copy = os.path.join('modeldir/fashionmnist-npd-defended/')\n",
    "defended_saver.restore(sess, tf.train.latest_checkpoint(logdir_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 12.24%\n"
     ]
    }
   ],
   "source": [
    "compute_agreement_and_accuracy(true_model, copy_model, sess, test_dsl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.17 64-bit ('.env': virtualenv)",
   "language": "python",
   "name": "python271764bitenvvirtualenvb42ac99cf11b4ee1bb37b11bd5fed573"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
